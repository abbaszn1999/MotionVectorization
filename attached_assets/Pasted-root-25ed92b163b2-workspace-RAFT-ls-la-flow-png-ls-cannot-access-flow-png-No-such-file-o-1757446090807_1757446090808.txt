root@25ed92b163b2:/workspace/RAFT# ls -la flow_*.png
ls: cannot access 'flow_*.png': No such file or directory
root@25ed92b163b2:/workspace/RAFT# nvidia-smi
Tue Sep  9 19:27:46 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A6000               On  |   00000000:0F:00.0 Off |                  Off |
| 30%   26C    P8             21W /  300W |       0MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
root@25ed92b163b2:/workspace/RAFT# python demo.py --model=models/raft-things.pth --path=video_frames --small
Traceback (most recent call last):
  File "/workspace/RAFT/demo.py", line 75, in <module>
    demo(args)
  File "/workspace/RAFT/demo.py", line 44, in demo
    model.load_state_dict(torch.load(args.model))
  File "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for DataParallel:
        Missing key(s) in state_dict: "module.fnet.layer1.0.conv3.weight", "module.fnet.layer1.0.conv3.bias", "module.fnet.layer1.1.conv3.weight", "module.fnet.layer1.1.conv3.bias", "module.fnet.layer2.0.conv3.weight", "module.fnet.layer2.0.conv3.bias", "module.fnet.layer2.1.conv3.weight", "module.fnet.layer2.1.conv3.bias", "module.fnet.layer3.0.conv3.weight", "module.fnet.layer3.0.conv3.bias", "module.fnet.layer3.1.conv3.weight", "module.fnet.layer3.1.conv3.bias", "module.cnet.layer1.0.conv3.weight", "module.cnet.layer1.0.conv3.bias", "module.cnet.layer1.1.conv3.weight", "module.cnet.layer1.1.conv3.bias", "module.cnet.layer2.0.conv3.weight", "module.cnet.layer2.0.conv3.bias", "module.cnet.layer2.1.conv3.weight", "module.cnet.layer2.1.conv3.bias", "module.cnet.layer3.0.conv3.weight", "module.cnet.layer3.0.conv3.bias", "module.cnet.layer3.1.conv3.weight", "module.cnet.layer3.1.conv3.bias", "module.update_block.gru.convz.weight", "module.update_block.gru.convz.bias", "module.update_block.gru.convr.weight", "module.update_block.gru.convr.bias", "module.update_block.gru.convq.weight", "module.update_block.gru.convq.bias".
        Unexpected key(s) in state_dict: "module.cnet.norm1.weight", "module.cnet.norm1.bias", "module.cnet.norm1.running_mean", "module.cnet.norm1.running_var", "module.cnet.norm1.num_batches_tracked", "module.cnet.layer1.0.norm1.weight", "module.cnet.layer1.0.norm1.bias", "module.cnet.layer1.0.norm1.running_mean", "module.cnet.layer1.0.norm1.running_var", "module.cnet.layer1.0.norm1.num_batches_tracked", "module.cnet.layer1.0.norm2.weight", "module.cnet.layer1.0.norm2.bias", "module.cnet.layer1.0.norm2.running_mean", "module.cnet.layer1.0.norm2.running_var", "module.cnet.layer1.0.norm2.num_batches_tracked", "module.cnet.layer1.1.norm1.weight", "module.cnet.layer1.1.norm1.bias", "module.cnet.layer1.1.norm1.running_mean", "module.cnet.layer1.1.norm1.running_var", "module.cnet.layer1.1.norm1.num_batches_tracked", "module.cnet.layer1.1.norm2.weight", "module.cnet.layer1.1.norm2.bias", "module.cnet.layer1.1.norm2.running_mean", "module.cnet.layer1.1.norm2.running_var", "module.cnet.layer1.1.norm2.num_batches_tracked", "module.cnet.layer2.0.norm1.weight", "module.cnet.layer2.0.norm1.bias", "module.cnet.layer2.0.norm1.running_mean", "module.cnet.layer2.0.norm1.running_var", "module.cnet.layer2.0.norm1.num_batches_tracked", "module.cnet.layer2.0.norm2.weight", "module.cnet.layer2.0.norm2.bias", "module.cnet.layer2.0.norm2.running_mean", "module.cnet.layer2.0.norm2.running_var", "module.cnet.layer2.0.norm2.num_batches_tracked", "module.cnet.layer2.0.norm3.weight", "module.cnet.layer2.0.norm3.bias", "module.cnet.layer2.0.norm3.running_mean", "module.cnet.layer2.0.norm3.running_var", "module.cnet.layer2.0.norm3.num_batches_tracked", "module.cnet.layer2.0.downsample.1.weight", "module.cnet.layer2.0.downsample.1.bias", "module.cnet.layer2.0.downsample.1.running_mean", "module.cnet.layer2.0.downsample.1.running_var", "module.cnet.layer2.0.downsample.1.num_batches_tracked", "module.cnet.layer2.1.norm1.weight", "module.cnet.layer2.1.norm1.bias", "module.cnet.layer2.1.norm1.running_mean", "module.cnet.layer2.1.norm1.running_var", "module.cnet.layer2.1.norm1.num_batches_tracked", "module.cnet.layer2.1.norm2.weight", "module.cnet.layer2.1.norm2.bias", "module.cnet.layer2.1.norm2.running_mean", "module.cnet.layer2.1.norm2.running_var", "module.cnet.layer2.1.norm2.num_batches_tracked", "module.cnet.layer3.0.norm1.weight", "module.cnet.layer3.0.norm1.bias", "module.cnet.layer3.0.norm1.running_mean", "module.cnet.layer3.0.norm1.running_var", "module.cnet.layer3.0.norm1.num_batches_tracked", "module.cnet.layer3.0.norm2.weight", "module.cnet.layer3.0.norm2.bias", "module.cnet.layer3.0.norm2.running_mean", "module.cnet.layer3.0.norm2.running_var", "module.cnet.layer3.0.norm2.num_batches_tracked", "module.cnet.layer3.0.norm3.weight", "module.cnet.layer3.0.norm3.bias", "module.cnet.layer3.0.norm3.running_mean", "module.cnet.layer3.0.norm3.running_var", "module.cnet.layer3.0.norm3.num_batches_tracked", "module.cnet.layer3.0.downsample.1.weight", "module.cnet.layer3.0.downsample.1.bias", "module.cnet.layer3.0.downsample.1.running_mean", "module.cnet.layer3.0.downsample.1.running_var", "module.cnet.layer3.0.downsample.1.num_batches_tracked", "module.cnet.layer3.1.norm1.weight", "module.cnet.layer3.1.norm1.bias", "module.cnet.layer3.1.norm1.running_mean", "module.cnet.layer3.1.norm1.running_var", "module.cnet.layer3.1.norm1.num_batches_tracked", "module.cnet.layer3.1.norm2.weight", "module.cnet.layer3.1.norm2.bias", "module.cnet.layer3.1.norm2.running_mean", "module.cnet.layer3.1.norm2.running_var", "module.cnet.layer3.1.norm2.num_batches_tracked", "module.update_block.mask.0.weight", "module.update_block.mask.0.bias", "module.update_block.mask.2.weight", "module.update_block.mask.2.bias", "module.update_block.encoder.convc2.weight", "module.update_block.encoder.convc2.bias", "module.update_block.gru.convz1.weight", "module.update_block.gru.convz1.bias", "module.update_block.gru.convr1.weight", "module.update_block.gru.convr1.bias", "module.update_block.gru.convq1.weight", "module.update_block.gru.convq1.bias", "module.update_block.gru.convz2.weight", "module.update_block.gru.convz2.bias", "module.update_block.gru.convr2.weight", "module.update_block.gru.convr2.bias", "module.update_block.gru.convq2.weight", "module.update_block.gru.convq2.bias".
        size mismatch for module.fnet.conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([32, 3, 7, 7]).
        size mismatch for module.fnet.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for module.fnet.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 32, 1, 1]).
        size mismatch for module.fnet.layer1.0.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.fnet.layer1.0.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).
        size mismatch for module.fnet.layer1.0.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.fnet.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 32, 1, 1]).
        size mismatch for module.fnet.layer1.1.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.fnet.layer1.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).
        size mismatch for module.fnet.layer1.1.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.fnet.layer2.0.conv1.weight: copying a param with shape torch.Size([96, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).
        size mismatch for module.fnet.layer2.0.conv1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.fnet.layer2.0.conv2.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).
        size mismatch for module.fnet.layer2.0.conv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.fnet.layer2.0.downsample.0.weight: copying a param with shape torch.Size([96, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 1, 1]).
        size mismatch for module.fnet.layer2.0.downsample.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).
        size mismatch for module.fnet.layer2.1.conv1.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 64, 1, 1]).
        size mismatch for module.fnet.layer2.1.conv1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.fnet.layer2.1.conv2.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).
        size mismatch for module.fnet.layer2.1.conv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.fnet.layer3.0.conv1.weight: copying a param with shape torch.Size([128, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 64, 1, 1]).
        size mismatch for module.fnet.layer3.0.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.fnet.layer3.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 24, 3, 3]).
        size mismatch for module.fnet.layer3.0.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.fnet.layer3.0.downsample.0.weight: copying a param with shape torch.Size([128, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 64, 1, 1]).
        size mismatch for module.fnet.layer3.0.downsample.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([96]).
        size mismatch for module.fnet.layer3.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).
        size mismatch for module.fnet.layer3.1.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.fnet.layer3.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 24, 3, 3]).
        size mismatch for module.fnet.layer3.1.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.fnet.conv2.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 96, 1, 1]).
        size mismatch for module.fnet.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
        size mismatch for module.cnet.conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([32, 3, 7, 7]).
        size mismatch for module.cnet.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for module.cnet.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 32, 1, 1]).
        size mismatch for module.cnet.layer1.0.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.cnet.layer1.0.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).
        size mismatch for module.cnet.layer1.0.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.cnet.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 32, 1, 1]).
        size mismatch for module.cnet.layer1.1.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.cnet.layer1.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).
        size mismatch for module.cnet.layer1.1.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([8]).
        size mismatch for module.cnet.layer2.0.conv1.weight: copying a param with shape torch.Size([96, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).
        size mismatch for module.cnet.layer2.0.conv1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.cnet.layer2.0.conv2.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).
        size mismatch for module.cnet.layer2.0.conv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.cnet.layer2.0.downsample.0.weight: copying a param with shape torch.Size([96, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 1, 1]).
        size mismatch for module.cnet.layer2.0.downsample.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([64]).
        size mismatch for module.cnet.layer2.1.conv1.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 64, 1, 1]).
        size mismatch for module.cnet.layer2.1.conv1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.cnet.layer2.1.conv2.weight: copying a param with shape torch.Size([96, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).
        size mismatch for module.cnet.layer2.1.conv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([16]).
        size mismatch for module.cnet.layer3.0.conv1.weight: copying a param with shape torch.Size([128, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 64, 1, 1]).
        size mismatch for module.cnet.layer3.0.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.cnet.layer3.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 24, 3, 3]).
        size mismatch for module.cnet.layer3.0.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.cnet.layer3.0.downsample.0.weight: copying a param with shape torch.Size([128, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 64, 1, 1]).
        size mismatch for module.cnet.layer3.0.downsample.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([96]).
        size mismatch for module.cnet.layer3.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).
        size mismatch for module.cnet.layer3.1.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.cnet.layer3.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 24, 3, 3]).
        size mismatch for module.cnet.layer3.1.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([24]).
        size mismatch for module.cnet.conv2.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 96, 1, 1]).
        size mismatch for module.cnet.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([160]).
        size mismatch for module.update_block.encoder.convc1.weight: copying a param with shape torch.Size([256, 324, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 196, 1, 1]).
        size mismatch for module.update_block.encoder.convc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).
        size mismatch for module.update_block.encoder.convf1.weight: copying a param with shape torch.Size([128, 2, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 7, 7]).
        size mismatch for module.update_block.encoder.convf1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
        size mismatch for module.update_block.encoder.convf2.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 64, 3, 3]).
        size mismatch for module.update_block.encoder.convf2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for module.update_block.encoder.conv.weight: copying a param with shape torch.Size([126, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 128, 3, 3]).
        size mismatch for module.update_block.encoder.conv.bias: copying a param with shape torch.Size([126]) from checkpoint, the shape in current model is torch.Size([80]).
        size mismatch for module.update_block.flow_head.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 96, 3, 3]).
        size mismatch for module.update_block.flow_head.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
        size mismatch for module.update_block.flow_head.conv2.weight: copying a param with shape torch.Size([2, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([2, 128, 3, 3]).
root@25ed92b163b2:/workspace/RAFT#