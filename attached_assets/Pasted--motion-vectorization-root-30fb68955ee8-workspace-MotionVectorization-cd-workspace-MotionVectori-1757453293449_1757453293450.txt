(motion_vectorization) root@30fb68955ee8:/workspace/MotionVectorization# cd /workspace/MotionVectorization/RAFT

# تشغيل مع GPU مباشرة (تجاهل التحقق)
python3 -c "
import torch
print('CUDA check:', torch.cuda.is_available())
if torch.cuda.is_available():
    print('GPU Name:', torch.cuda.get_device_name(0))
    print('Memory:', torch.cuda.get_device_properties(0).total_memory / 1e9, 'GB')
"
CUDA check: True
GPU Name: NVIDIA RTX A6000
Memory: 50.908823552 GB
(motion_vectorization) root@30fb68955ee8:/workspace/MotionVectorization/RAFT# cd /workspace/MotionVectorization

# إصلاح ملف extract_flow.py لاستخدام GPU فعلياً
cat > RAFT/extract_flow.py << 'EOF'
import sys
sys.path.append('core')

import argparse
import os
import cv2
import glob
import numpy as np
import torch
from PIL import Image
import torch.nn.functional as F

from core.raft import RAFT
from core.utils import flow_viz
from core.utils.utils import InputPadder
from tqdm import tqdm

# استخدام GPU مباشرة
DEVICE = 'cuda'
print(f"Using device: {DEVICE}")
print(f"GPU Name: {torch.cuda.get_device_name(0)}")
print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

def load_image(imfile, max_size=512):
    img = Image.open(imfile)
    w, h = img.size
    if w > max_size and h > max_size:
        if w > h:
            img = img.resize((512, int(h * 512 / w)))
        else:
            img = img.resize((int(w * 512 / h), 512))
    img = np.array(Image.open(imfile)).astype(np.uint8)
    img = torch.from_numpy(img).permute(2, 0, 1).float()
    return img[None].to(DEVICE)

def warp(x, flo):
    B, C, H, W = x.size()
    xx = torch.arange(0, W).view(1, -1).repeat(H, 1)
    yy = torch.arange(0, H).view(-1, 1).repeat(1, W)
    xx = xx.view(1, 1, H, W).repeat(B, 1, 1, 1)
    yy = yy.view(1, 1, H, W).repeat(B, 1, 1, 1)
    grid = torch.cat((xx, yy), 1).float()

    if x.is_cuda:
        grid = grid.cuda()
    vgrid = grid + flo
    vgrid[:, 0, :, :] = 2.0 * vgrid[:, 0, :, :].clone() / max(W - 1, 1) - 1.0
    vgrid[:, 1, :, :] = 2.0 * vgrid[:, 1, :, :].clone() / max(H - 1, 1) - 1.0

    vgrid = vgrid.permute(0, 2, 3, 1)
    output = F.grid_sample(x, vgrid, align_corners=True)
python3 extract_flow.py --path "../videos/test1" --model "models/raft-sintel.pth" --max_frames 300 --add_backl flow')
Using device: cuda
GPU Name: NVIDIA RTX A6000
GPU Memory: 50.9 GB
Model loaded on cuda
0it [00:00, ?it/s]/opt/miniconda3/envs/motion_vectorization/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/envs/bld/conda-bld/pytorch-select_1725570624180/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
/opt/miniconda3/envs/motion_vectorization/lib/python3.8/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/envs/bld/conda-bld/pytorch-select_1725570624180/work/aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
34it [00:31,  1.07it/s]
(motion_vectorization) root@30fb68955ee8:/workspace/MotionVectorization/RAFT# 